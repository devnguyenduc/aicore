{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import create_lstm_model as lstm\n",
    "import read_video_and_labels as r\n",
    "import utils\n",
    "\n",
    "# Khởi tạo TensorFlow session và cấu hình GPU\n",
    "# Đảm bảo rằng không có phiên làm việc TensorFlow khác đang sử dụng GPU\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "# Cài đặt giới hạn bộ nhớ GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Thêm GPU vào môi trường đồ họa nhất quán và đặt giới hạn bộ nhớ GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "        # Xóa biểu đồ tính toán mặc định của TensorFlow và giải phóng bộ nhớ\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Resource path\n",
    "resource_path = 'resource/trending/'\n",
    "\n",
    "# nickname testing\n",
    "nickname = 'ig_yangg'\n",
    "nickname_test = 'hahongnguyen'\n",
    "\n",
    "# Đường dẫn tới file video và file labels của bạn\n",
    "video_path = resource_path + 'video/' + nickname + '.mp4'\n",
    "labels_path = resource_path + 'labels/' + nickname + '_labels.csv'\n",
    "\n",
    "# Đường dẫn tới file video và file labels của bạn\n",
    "video_path_test = resource_path + 'video/' + nickname_test + '.mp4'\n",
    "labels_path_test = resource_path + 'labels/' + nickname_test + '_labels.csv'\n",
    "\n",
    "# Gọi hàm để đọc video và nhãn từ file và chuyển đổi thành X_train và y_train\n",
    "X_data, y_data = r.read_video_and_labels(video_path, labels_path)\n",
    "\n",
    "# X_test, y_test = r.read_video_and_labels(video_path_test, labels_path_test)\n",
    "\n",
    "print(X_data.shape)\n",
    "\n",
    "# Chuẩn bị dữ liệu và định dạng\n",
    "X_data_flat = utils.flatten_and_renormalize(X_data)\n",
    "# X_test_flat = utils.flatten_and_renormalize(X_test)\n",
    "\n",
    "print(X_data_flat.shape)\n",
    "\n",
    "\n",
    "# Chuyển đổi X_train_flat thành mảng 3D với time_steps = 64 và input_dim = 1024 * 576 * 3\n",
    "input_shape = X_data_flat.shape[1:] # Kích thước dữ liệu đầu vào (số khung hình trong chuỗi, chiều rộng khung hình, chiều cao khung hình, số kênh màu)\n",
    "\n",
    "print(input_shape)\n",
    "\n",
    "num_classes = y_data.shape[1]\n",
    "# Tạo mô hình\n",
    "model = lstm.create_lstm_model(input_shape, num_classes)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# data là tensor (64, 1769472)\n",
    "data_split = np.array_split(X_data_flat, 10, axis=0)\n",
    "\n",
    "# Chuyển các phần dữ liệu thành tensor trên GPU\n",
    "data_tensors_gpu = [tf.constant(part, dtype=tf.float32) for part in data_split]\n",
    "\n",
    "# Dữ liệu huấn luyện và nhãn tương ứng\n",
    "X_train = data_tensors_gpu[:-1]  # 9 phần dữ liệu huấn luyện (sử dụng tất cả ngoại trừ phần cuối cùng)\n",
    "y_train = y_data[:-1]  # 9 nhãn tương ứng với 9 phần dữ liệu huấn luyện\n",
    "\n",
    "# Dữ liệu validation và nhãn tương ứng\n",
    "X_val = data_tensors_gpu[-1]  # Phần cuối cùng dùng làm validation data\n",
    "y_val = y_data[-1]  # Nhãn tương ứng với phần cuối cùng dùng làm validation data\n",
    "\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "# Khởi tạo các tham số huấn luyện\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "validation_split = 0.2\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split)\n",
    "#\n",
    "# loss, accuracy = model.evaluate(X_val, y_val)\n",
    "# print(f\"Test loss: {loss:.4f}\")\n",
    "# print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Huấn luyện mô hình trên các phần dữ liệu huấn luyện\n",
    "for epoch in range(epochs):\n",
    "    # for i in range(0, len(X_train), batch_size):\n",
    "    #     print(i)\n",
    "    X_batch = tf.concat(X_train[0:batch_size], axis=0)\n",
    "    y_batch = tf.concat(y_train[0:batch_size], axis=0)\n",
    "\n",
    "    # Train mô hình trên batch hiện tại\n",
    "    print(\"train with i: \", i)\n",
    "    loss = model.train_on_batch(X_batch, y_batch)\n",
    "\n",
    "    utils.save_model(model, str(epoch) + 'trained_model.h5')\n",
    "\n",
    "    # Tải mô hình đã lưu\n",
    "    loaded_model = utils.load_model('resource/aimodel/' + nickname + \".h5\")\n",
    "\n",
    "    # Đánh giá mô hình trên dữ liệu validation sau mỗi epoch\n",
    "    val_loss = model.evaluate(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {loss} - Validation Loss: {val_loss}\")\n",
    "\n",
    "# model.fit(X_train_flat_gpu, np.array(y_train), batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Lưu mô hình đã huấn luyện\n",
    "\n",
    "\n",
    "# Đánh giá mô hình trên tập dữ liệu kiểm tra\n",
    "# loss, accuracy = loaded_model.evaluate(X_test_flat.shape[1:], y_test)\n",
    "\n",
    "# print(f'Test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
